# ğŸ¨ guggenheim_scraper

## Project Description

**guggenheim_scraper** is a Python project designed to collect, clean, and explore data from the Peggy Guggenheim Museumâ€™s collection in Venice.

The project builds a comprehensive database of artworks and provides insights into artist representation, historical periods, and the display/storage status of the collection.

This is an end-to-end workflow: from web scraping to cleaned datasets, ready for analysis and visualization.


## ğŸ“‚ Repository Contents

### Dataset

- **gughenheim-venezia-opere-tutte-le-pagine-csv.csv**  
  The full dataset of artworks scraped from the museum website, cleaned and structured.

### ğŸ““ Notebooks

- **scraping_gughenem.ipynb**  
  Contains all the code to:
  - ğŸ•¸ï¸ Scrape the museum website using BeautifulSoup  
  - ğŸ’¾ Save the raw dataset for further cleaning  

### ğŸ§¹ Data Cleaning

- Data cleaning and standardization were performed using **OpenRefine**, to handle inconsistencies, normalize artist names, and structure the dataset for analysis.

### ğŸ“Š Project Presentations

- **Peggy_Guggenheim_Part_1.pdf**  
- **Peggy_Guggenheim_Part_2.pdf**

Presentations of the work carried out for the project.  
The first presentation focuses on **data scraping and data cleaning**, while the second presentation focuses on **data presentation and dashboard creation**.


## ğŸ¯ Project Objectives

- ğŸ•µï¸ Scrape structured data on the Peggy Guggenheim Collection using BeautifulSoup  
- ğŸ§¹ Clean, normalize, and standardize data with OpenRefine  
- ğŸ“Š Explore trends: most represented artists, display vs storage status, historical periods  
- ğŸ“ˆ Prepare the data for visualization and dashboards  
- ğŸ”„ Provide a reproducible workflow from scraping to cleaned dataset  


## ğŸ› ï¸ Tools & Technologies

- **Python** â€” Core scripting and data processing  
- **Jupyter Notebook** â€” Interactive workflow for scraping  
- **BeautifulSoup** â€” Web scraping library for extracting artwork data  
- **OpenRefine** â€” Data cleaning and normalization tool  
- **CSV** â€” For storing cleaned datasets  
- **Tableau** â€” Data visualization and dashboard creation  


## ğŸ“ Project File Structure

| File / Folder | Description |
|---------------|-------------|
| `gughenheim_scraper/` | Main project directory |
| `gughenheim-venezia-opere-tutte-le-pagine-csv.csv` | Full cleaned dataset of artworks from the museum |
| `scraping_gughenem.ipynb` | Jupyter Notebook containing scraping code |
| `Peggy_Guggenheim_Part_1.pdf` | Presentation focused on data scraping & cleaning |
| `Peggy_Guggenheim_Part_2.pdf` | Presentation focused on data visualization & dashboard |
| `README.md` | Project documentation |

                                     

## ğŸ’¡ Highlights

- Full Python end-to-end workflow ğŸ  
- Insightful exploration of a world-famous modern art collection ğŸ–¼ï¸  
- Portfolio-ready project showcasing web scraping with BeautifulSoup and data cleaning with OpenRefine ğŸ’»

___

## ğŸ“Š Explore the interactive Tableau dashboard: [Click here](https://public.tableau.com/app/profile/giovanna.pichierri/viz/Peggy_Guggenheim_collection/Dashboard1)

